# Few-shot Text Classification using Setfit

Few-shot learning is a subfield of machine learning that aims to enable a model to generalize to new tasks with just a few examples. This is in contrast to traditional machine learning which typically requires a large amount of labeled data to train a model. In few-shot learning, the model is trained on a small number of examples, often as few as one or two per class, and is expected to be able to classify new examples from previously unseen classes. Few-shot learning has applications in a wide range of domains, including computer vision, natural language processing, and robotics.

## Advantages

Few-shot learning has several advantages over traditional machine learning methods:

- **Reduced data requirements:** Few-shot learning can achieve good performance with much less labeled data than traditional machine learning methods. This is particularly useful in domains where obtaining labeled data is difficult or expensive.
- **Flexibility:** Few-shot learning models can be adapted to new tasks quickly and easily, making them useful in scenarios where new tasks arise frequently.
- **Generalization:** Few-shot learning models are designed to generalize to new tasks with just a few examples, making them useful in scenarios where the number of classes or tasks is large and constantly changing.
- **Efficiency:** Few-shot learning can be more computationally efficient than traditional machine learning methods, as it requires less data and fewer training iterations.

## Code Demo

All of the steps are done in ascending order in the `few_shot_text_classification.ipynb` notebook.

## Resources

- Original Repository of the library: https://github.com/pmbaumgartner/setfit
- Blog: https://towardsdatascience.com/sentence-transformer-fine-tuning-setfit-outperforms-gpt-3-on-few-shot-text-classification-while-d9a3788f0b4e 
- Dataset: https://www.kaggle.com/competitions/sentiment-analysis-on-movie-reviews 
- Video Tutorial: https://youtu.be/wNYxw4j90RI 